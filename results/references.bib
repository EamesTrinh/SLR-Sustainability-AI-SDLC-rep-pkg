// MISC

@misc{kitchenham_guidelines_2007,
	title = {Guidelines for performing {Systematic} {Literature} {Reviews} in {Software} {Engineering}},
	urldate = {2023-11-11},
	author = {Kitchenham, Barbara},
	month = jul,
	year = {2007},
}

@ARTICLE{sun_apple_2019,
  author={Sun, Yongquan and Kong, Lingxi and Abbas Khan, Hassan and Pecht, Michael G.},
  journal={IEEE Access}, 
  title={Li-ion Battery Reliability – A Case Study of the Apple iPhone®}, 
  year={2019},
  volume={7},
  number={},
  pages={71131-71141},
  doi={10.1109/ACCESS.2019.2918401}}

@article{haddaway_role_2015,
	title = {The {Role} of {Google} {Scholar} in {Evidence} {Reviews} and {Its} {Applicability} to {Grey} {Literature} {Searching}},
	volume = {10},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0138237},
	doi = {10.1371/journal.pone.0138237},
	language = {en},
	number = {9},
	urldate = {2023-12-08},
	journal = {PLOS ONE},
	author = {Haddaway, Neal Robert and Collins, Alexandra Mary and Coughlin, Deborah and Kirk, Stuart},
	editor = {Wray, K. Brad},
	month = sep,
	year = {2015},
	pages = {e0138237},
}


@article{nti_applications_2022,
	title = {Applications of artificial intelligence in engineering and manufacturing: a systematic review},
	volume = {33},
	issn = {0956-5515, 1572-8145},
	shorttitle = {Applications of artificial intelligence in engineering and manufacturing},
	url = {https://link.springer.com/10.1007/s10845-021-01771-6},
	doi = {10.1007/s10845-021-01771-6},
	abstract = {Engineering and manufacturing processes and systems designs involve many challenges, such as dynamism, chaotic behaviours, and complexity. Of late, the arrival of big data, high computational speed, cloud computing and artificial intelligence techniques (like machine learning and deep learning) has reformed how many engineering and manufacturing professionals approach their work. These technologies offer thrilling innovative ways for engineers and manufacturers to tackle real-life challenges. On the other hand, the field of Artificial Intelligence (AI) is extensive. Several diverse theories, algorithms, and methods are available, which presents a challenge and a barrier in choosing the right AI technique for the appropriate engineering process or manufacturing process and environments. Besides, the pertinent literature is disseminated over various journals, conference proceedings, and research communities. Hence, conducting a systematic survey to scrutinise and classify the existing literature is worthwhile. However, it is challenging, but previous review studies have not adequately addressed AI’s use and advancement in engineering and manufacturing (EM). Besides, some concentrated on single AI models, and others focused on a specific area in EM. This paper presents a comprehensive systematic review of studies on AI and its application in EM. To limit the scope of the current study, we conducted a keyword search in official publisher websites and academic databases, such as Springer, Elsevier, Scopus, Science Publication, Taylor \& Francis, Directory of Open Access Journals (DOAJ), Association for Computing Machinery (ACM), Wiley online library, Inderscience and Google scholar. The search results (173 articles) were filtered according to a proposed framework, which resulted in ninety-one (91) relevant research articles. We reviewed the articles based on a proposed taxonomy (the year of publication, the AI algorithm and machine learning task adopted, the application area in EM, the train and test split of data, the error, and accuracy metrics used, the potential benefits). Our assessment using the proposed taxonomy gave a helpful insight into the literature’s anatomy on various AI applications in engineering and manufacturing. Also, we identified opportunities for future research in AI application in the field of EM.},
	language = {en},
	number = {6},
	urldate = {2023-12-09},
	journal = {Journal of Intelligent Manufacturing},
	author = {Nti, Isaac Kofi and Adekoya, Adebayo Felix and Weyori, Benjamin Asubam and Nyarko-Boateng, Owusu},
	month = aug,
	year = {2022},
	pages = {1581--1601},
}

@article{lee_survey_2024,
	title = {A survey of energy concerns for software engineering},
	volume = {210},
	issn = {01641212},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0164121223003394},
	doi = {10.1016/j.jss.2023.111944},
	abstract = {There is growing attention to energy efficiency in the software engineering field. This has been driven by modern technologies, for example, Internet of Things (IoT), Social Networking Services (SNS) and quantum computing. In addition to this, recent trends and concerns such as Environment, Social, and Governance (ESG) and human/societal/environmental well-being for responsible Artificial Intelligence (AI) have accelerated the use of energy efficient software. Despite this, energy concerns in this field have been less explored and studied. This limitation results in falling short to address and overcome greenability issues at the software level, and leaving critical challenges to be solved in this space. This study aims to address this limitation and fill the gap between previous studies. We survey green in software engineering framed by the ten knowledge areas of software engineering to not only cover the entire development life-cycle but also widen the scope of discussion to software process, method, and model management. Based on our comprehensive investigation, we discuss open challenges, trade-offs and implications of this study for both researchers and practitioners.},
	language = {en},
	urldate = {2024-01-16},
	journal = {Journal of Systems and Software},
	author = {Lee, Sung Une and Fernando, Niroshinie and Lee, Kevin and Schneider, Jean-Guy},
	month = apr,
	year = {2024},
	pages = {111944},
}

@book{wohlin_experimentation_2000,
	series = {International {Series} in {Software} {Engineering}},
	title = {Experimentation in {Software} {Engineering}: {An} {Introduction}},
	isbn = {978-1-4613-7091-8},
	number = {6},
	publisher = {Springer},
	author = {Wohlin, Claes and Runeson, Per and Höst, Martin and Ohlsson, Magnus and Regnell, Björn and Wesslén, Anders},
	year = {2000},
}

@book{bourque_guide_2014,
	edition = {3},
	title = {Guide to the {Software} {Engineering} {Body} of {Knowledge} ({SWEBOK})},
	isbn = {0-7695-5166-1},
	publisher = {IEEE},
	author = {Bourque, Pierre and Fairley, Richard},
	year = {2014},
}

// SDLC //////////


@article{balaji_wateerfallvs_2012,
	title = {{WATEERFALLVs} {V}-{MODEL} {Vs} {AGILE}: {A} {COMPARATIVE} {STUDY} {ON} {SDLC}},
	abstract = {Organizations that are developing software solution are faced with the difficult choice of picking the right software development life cycle (SDLC). The waterfall model is a sequential design process, often used in software development processes, in which progress is seen as flowing steadily downwards (like a waterfall) through the phases. The V-model represents a software development process which may be considered an extension of the waterfall model. Instead of moving down in a linear way, the process steps are bent upwards after the coding phase, to form the typical V shape Agile Modeling is a practice-based methodology for modelling and documentation of software-based systems. It is intended to be a collection of values, principles, and practices for modelling software that can be applied on a software development project in a more flexible manner than traditional Modelling methods. This comparative summarizes the steps an organization would have to go through in order to make the best possible choice.},
	language = {en},
	number = {1},
	journal = {. Vol.},
	author = {Balaji, S},
	year = {2012},
}

@article{alshamrani_comparison_2015,
	title = {A {Comparison} {Between} {Three} {SDLC} {Models} {Waterfall} {Model}, {Spiral} {Model}, and {Incremental}/{Iterative} {Model}},
	volume = {12},
	url = {https://d1wqtxts1xzle7.cloudfront.net/36637147/SDLC-libre.pdf?1423940228=&response-content-disposition=inline%3B+filename%3DA_Comparison_Between_Three_SDLC_Models_W.pdf&Expires=1700143179&Signature=cxfSrQOviA9fPLieh~7q71qBOaHfkTN8nFM3nmrk9YviTkR2Bc4w2RAlFLMWuBqE2JyxerIA-8sMDYdRKTcBYhs3CJ80qk5DM0XgLjRpf5DuI7Iyaq-3QE8Tc-uF9lGH5yi1KbFls90oVuHiRom0aUVaMX-X-kDh-abnM~fcp842-awq0~eHzvRXB8YbL1kAlps9p2WLtL1lgvSkI5wCbWRIm6apy9cejxB5bmp7STzzLCL-TPoflAjdlgfxosleIhUbFESra56BoKMRwGsox2GSydU9bzz2dG66V3fyCmF1uBAPLwbeRQ~rWam7YkRnMXt39AJ8XQY9tt8c4dukRg__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA},
	number = {1},
	urldate = {2023-11-16},
	journal = {IJCSI International Journal of Computer Science Issues},
	author = {Alshamrani, Adel and Bahattab, Abdullah},
	month = jan,
	year = {2015},
}

@article{radack_system_nodate,
	title = {{THE} {SYSTEM} {DEVELOPMENT} {LIFE} {CYCLE} ({SDLC})},
	language = {en},
	author = {Radack, Shirley},
}

@article{ruparelia_software_2010,
	title = {Software development lifecycle models},
	volume = {35},
	issn = {0163-5948},
	url = {https://dl.acm.org/doi/10.1145/1764810.1764814},
	doi = {10.1145/1764810.1764814},
	abstract = {This history column article provides a tour of the main software development life cycle (SDLC) models. (A lifecycle covers all the stages of software from its inception with requirements definition through to fielding and maintenance.) System development lifecycle models have drawn heavily on software and so the two terms can be used interchangeably in terms of SDLC, especially since software development in this respect encompasses software systems development. Because the merits of selecting and using an SDLC vary according to the environment in which software is developed as well as its application, I discuss three broad categories for consideration when analyzing the relative merits of SDLC models. I consider the waterfall model before the other models because it has had a profound effect on software development, and has additionally influenced many SDLC models prevalent today. Thereafter, I consider some of the mainstream models and finish with a discussion of what the future could hold for SDLC models.},
	language = {en},
	number = {3},
	urldate = {2024-02-10},
	journal = {ACM SIGSOFT Software Engineering Notes},
	author = {Ruparelia, Nayan B.},
	month = may,
	year = {2010},
	pages = {8--13},
}

@article{ragunath_evolving_2010,
	title = {Evolving {A} {New} {Model} ({SDLC} {Model}-2010) {For} {Software} {Development} {Life} {Cycle} ({SDLC})},
	abstract = {Structured project management techniques (such as an SDLC) enhance management’s control over projects by dividing complex tasks into manageable sections. A software life cycle model is either a descriptive or prescriptive characterization of how software is or should be developed. But none of the SDLC models discuss the key issues like Change management, Incident management and Release management processes within the SDLC process, but, it is addressed in the overall project management. In the proposed hypothetical model, the concept of user-developer interaction in the conventional SDLC model has been converted into a three dimensional model which comprises of the user, owner and the developer. In the proposed hypothetical model, the concept of user-developer interaction in the conventional SDLC model has been converted into a three dimensional model which comprises of the user, owner and the developer. The ―one size fits all‖ approach to applying SDLC methodologies is no longer appropriate. We have made an attempt to address the above mentioned defects by using a new hypothetical model for SDLC described elsewhere. The drawback of addressing these management processes under the overall project management is missing of key technical issues pertaining to software development process that is, these issues are talked in the project management at the surface level but not at the ground level.},
	language = {en},
	author = {Ragunath, PK and Velmourougan, S and Davachelvan, P and Kayalvizhi, S and Ravimohan, R},
	year = {2010},
}



// AI x SDLC


@article{shafiq_literature_2021,
	title = {A {Literature} {Review} of {Using} {Machine} {Learning} in {Software} {Development} {Life} {Cycle} {Stages}},
	volume = {9},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/9568959/},
	doi = {10.1109/ACCESS.2021.3119746},
	abstract = {The software engineering community is rapidly adopting machine learning for transitioning modern-day software towards highly intelligent and self-learning systems. However, the software engineering community is still discovering new ways how machine learning can offer help for various software development life cycle stages. In this article, we present a study on the use of machine learning across various software development life cycle stages. The overall aim of this article is to investigate the relationship between software development life cycle stages, and machine learning tools, techniques, and types. We attempt a holistic investigation in part to answer the question of whether machine learning favors certain stages and/or certain techniques.},
	language = {en},
	urldate = {2023-11-21},
	journal = {IEEE Access},
	author = {Shafiq, Saad and Mashkoor, Atif and Mayr-Dorn, Christoph and Egyed, Alexander},
	year = {2021},
	pages = {140896--140920},
}

@inproceedings{finnie-ansley_robots_2022,
	address = {Virtual Event Australia},
	title = {The {Robots} {Are} {Coming}: {Exploring} the {Implications} of {OpenAI} {Codex} on {Introductory} {Programming}},
	isbn = {978-1-4503-9643-1},
	shorttitle = {The {Robots} {Are} {Coming}},
	url = {https://dl.acm.org/doi/10.1145/3511861.3511863},
	doi = {10.1145/3511861.3511863},
	language = {en},
	urldate = {2023-11-25},
	booktitle = {Australasian {Computing} {Education} {Conference}},
	publisher = {ACM},
	author = {Finnie-Ansley, James and Denny, Paul and Becker, Brett A. and Luxton-Reilly, Andrew and Prather, James},
	month = feb,
	year = {2022},
	pages = {10--19},
}

@inproceedings{zamani_machine_2021,
	address = {Notre Dame, IN, USA},
	title = {Machine {Learning} in {Requirements} {Engineering}: {A} {Mapping} {Study}},
	isbn = {978-1-66541-898-0},
	shorttitle = {Machine {Learning} in {Requirements} {Engineering}},
	url = {https://ieeexplore.ieee.org/document/9582365/},
	doi = {10.1109/REW53955.2021.00023},
	urldate = {2023-11-25},
	booktitle = {2021 {IEEE} 29th {International} {Requirements} {Engineering} {Conference} {Workshops} ({REW})},
	publisher = {IEEE},
	author = {Zamani, Kareshna and Zowghi, Didar and Arora, Chetan},
	month = sep,
	year = {2021},
	pages = {116--125},
}

@article{bruneliere_aidoart_2022,
	title = {{AIDOaRt}: {AI}-augmented {Automation} for {DevOps}, a model-based framework for continuous development in {Cyber}–{Physical} {Systems}},
	volume = {94},
	issn = {01419331},
	shorttitle = {{AIDOaRt}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0141933122002022},
	doi = {10.1016/j.micpro.2022.104672},
	abstract = {The advent of complex Cyber–Physical Systems (CPSs) creates the need for more efficient engineering processes. Recently, DevOps promoted the idea of considering a closer continuous integration between system development (including its design) and operational deployment. Despite their use being still currently limited, Artificial Intelligence (AI) techniques are suitable candidates for improving such system engineering activities (cf. AIOps). In this context, AIDOaRT is a large European collaborative project that aims at providing AIaugmented automation capabilities to better support the modeling, coding, testing, monitoring, and continuous development of CPSs. The project proposes to combine Model Driven Engineering principles and techniques with AI-enhanced methods and tools for engineering more trustable CPSs. The resulting framework will (1) enable the dynamic observation and analysis of system data collected at both runtime and design time and (2) provide dedicated AI-augmented solutions that will then be validated in concrete industrial cases. This paper describes the main research objectives and underlying paradigms of the AIDOaRt project. It also introduces the conceptual architecture and proposed approach of the AIDOaRt overall solution. Finally, it reports on the actual project practices and discusses the current results and future plans.},
	language = {en},
	urldate = {2023-11-27},
	journal = {Microprocessors and Microsystems},
	author = {Bruneliere, Hugo and Muttillo, Vittoriano and Eramo, Romina and Berardinelli, Luca and Gómez, Abel and Bagnato, Alessandra and Sadovykh, Andrey and Cicchetti, Antonio},
	month = oct,
	year = {2022},
	pages = {104672},
}






// Sustainability x SDLC


@article{santoyo-castelazo_sustainability_2014,
	title = {Sustainability assessment of energy systems: integrating environmental, economic and social aspects},
	volume = {80},
	issn = {09596526},
	shorttitle = {Sustainability assessment of energy systems},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0959652614005381},
	doi = {10.1016/j.jclepro.2014.05.061},
	abstract = {Sustainable development of energy systems requires consideration of all three sustainability dimensions: environmental, economic and social. Current work presents a new decision-support framework for facilitating this. Taking a life cycle approach, the framework integrates the three sustainability dimensions to enable assessments at both technology and systems levels. The framework comprises scenario analysis, life cycle assessment, life cycle costing, social sustainability assessment and multicriteria decision analysis, which are used to assess and identify the most sustainable energy options. The application of the framework is illustrated on the example of future electricity supply in Mexico. Eleven scenarios up to 2050 have been developed considering different technologies, electricity mixes and climate change targets. The results show that, based on the 17 sustainability criteria used in this work, the business-as-usual scenario, mostly based on fossil fuels, is unsustainable regardless of the preferences for different sustainability criteria. This is mainly due to the high costs and environmental impacts associated with fossil fuels. Overall, the most sustainable scenarios are those with higher penetration of renewables (wind, solar, hydro, geothermal and biomass) and nuclear power. These electricity pathways would enable meeting the national greenhouse gas emission targets by 2050 in a more sustainable way than envisaged by the current policy. However, some trade-offs among the sustainability criteria are needed, particularly with respect to the social impacts. These trade-offs can be explored easily within the decision-support framework to reveal how different stakeholder preferences affect the outcomes of sustainability assessment, thus contributing to more informed decision and policy making.},
	language = {en},
	urldate = {2023-11-17},
	journal = {Journal of Cleaner Production},
	author = {Santoyo-Castelazo, Edgar and Azapagic, Adisa},
	month = oct,
	year = {2014},
	pages = {119--138},
}

@article{lago_framing_2015,
	title = {Framing sustainability as a property of software quality},
	volume = {58},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/2714560},
	doi = {10.1145/2714560},
	abstract = {This framework addresses the environmental dimension of software performance, as applied here by a paper mill and a car-sharing service.},
	language = {en},
	number = {10},
	urldate = {2023-11-20},
	journal = {Communications of the ACM},
	author = {Lago, Patricia and Koçak, Sedef Akinli and Crnkovic, Ivica and Penzenstadler, Birgit},
	month = sep,
	year = {2015},
	pages = {70--78},
}

@article{mahmoud_green_2013,
	title = {A {Green} {Model} for {Sustainable} {Software} {Engineering}},
	volume = {7},
	abstract = {Information Communication Technology (ICT) has a strong impact on sustainable development due its rising demands for energy and resources needed when building hardware and software products. Most of the efforts spent on Green ICT/IT have been dedicated to addressing the effects of hardware on the environment but little have been considering the effects of building software products as well. Efficient software will indirectly consume less energy by using up less hardware equipment to run. Our contributions in this paper are devoted to building a two level green software model that covers the sustainable life cycle of a software product and the software tools promoting green and environmentally sustainable software. In the first level we propose a new green software engineering process that is a hybrid process between sequential, iterative, and agile development processes to produce an environmentally sustainable one. Each stage of the software process is then further studied to produce a green and sustainable stage. We propose either green guidelines or green processes for each software stage in the engineering process. We add to the software life cycle the requirements stage and the testing stage. We also include in the first level a complete list of metrics to measure the greenness of each stage in terms of the first order effects of ICT on the environment for a green software engineering process. No effort has been placed before in designing a green software engineering process. The second level explains how software itself can be used as a tool to aid in green computing by monitoring resources in an energy efficient manner. Finally, we show and explain relationships that can be found between the two levels in our proposed model to make the software engineering process and product green and sustainable.},
	language = {en},
	number = {4},
	journal = {International Journal of Software Engineering and Its Applications},
	author = {Mahmoud, Sara S and Ahmad, Imtiaz},
	year = {2013},
}

@article{zhu_programming_nodate,
	title = {A {Programming} {Model} for {Sustainable} {Software}},
	abstract = {This paper presents a novel energy-aware and temperature-aware programming model with ﬁrst-class support for sustainability. A program written in the new language, named Eco, may adaptively adjusts its own behaviors to stay on a given (energy or temperature) budget, avoiding both deﬁcit that would lead to battery drain or CPU overheating, and surplus that could have been used to improve the quality of results. Sustainability management in Eco is captured as a form of supply and demand matching, and the language runtime consistently maintains the equilibrium between supply and demand. Among the efforts of energy-adaptive and temperature-adaptive systems, Eco is distinctive in its role in bridging the programmer and the underlying system, and in particular, bringing both programmer knowledge and application-speciﬁc traits into energy optimization. Through a number of intuitive programming abstractions, Eco reduces challenging issues in this domain — such as workload characterization and decision making in adaptation —to simple programming tasks, ultimately offering ﬁne-grained, programmable, and declarative sustainability to energy-efﬁcient computing. Eco is an minimal extension to Java, and has been implemented as an open-source compiler. We validate the usefulness of Eco by upgrading real-world Java applications with energy awareness and temperature awareness.},
	language = {en},
	author = {Zhu, Haitao Steve and Lin, Chaoren and Liu, Yu David},
}

@article{verdecchia_green_2021,
	title = {Green {IT} and {Green} {Software}},
	volume = {38},
	issn = {0740-7459, 1937-4194},
	url = {https://ieeexplore.ieee.org/document/9585139/},
	doi = {10.1109/MS.2021.3102254},
	language = {en},
	number = {6},
	urldate = {2023-11-20},
	journal = {IEEE Software},
	author = {Verdecchia, Roberto and Lago, Patricia and Ebert, Christof and De Vries, Carol},
	month = nov,
	year = {2021},
	pages = {7--15},
}

@article{wiesner_software---loop_2023,
	title = {Software-in-the-loop simulation for developing and testing carbon-aware applications},
	volume = {53},
	issn = {1097-024X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.3275},
	doi = {10.1002/spe.3275},
	abstract = {The growing electricity demand of IT infrastructure has raised significant concerns about its carbon footprint. To mitigate the associated emissions of computing systems, current efforts therefore increasingly focus on aligning the power usage of software with the availability of clean energy. To operate, such carbon-aware applications require visibility and control over relevant metrics and configurations of the energy system. However, research and development of novel energy system abstraction layers and interfaces remain difficult due to the scarcity of available testing environments: Real testbeds are expensive to build and maintain, while existing simulation testbeds are unable to interact with real computing systems. To provide a widely applicable approach for developing and testing carbon-aware software, we propose a method for integrating real applications into a simulated energy system through software-in-the-loop simulation. The integration offers an API for accessing the energy system, while continuously modeling the computing system's power demand within the simulation. Our system allows for the integration of physical as well as virtual compute nodes, and can help accelerate research on carbon-aware computing systems in the future.},
	language = {en},
	number = {12},
	urldate = {2023-11-25},
	journal = {Software: Practice and Experience},
	author = {Wiesner, Philipp and Steinke, Marvin and Nickel, Henrik and Kitana, Yazan and Kao, Odej},
	year = {2023},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.3275},
	keywords = {co-simulation, energy-awareness, software-in-the-loop, sustainable computing, virtual energy system},
	pages = {2362--2376},
}

@article{mancebo_feetings_2021,
	title = {{FEETINGS}: {Framework} for {Energy} {Efficiency} {Testing} to {Improve} {Environmental} {Goal} of the {Software}},
	volume = {30},
	issn = {22105379},
	shorttitle = {{FEETINGS}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2210537921000494},
	doi = {10.1016/j.suscom.2021.100558},
	abstract = {Software is a fundamental part of today’s society. However, both users and software professionals need to be aware that its use impacts on the environment, due to the high energy consumption it entails. One of the main gaps to be faced is the difficulty of analyzing software energy consumption in the endeavor to know whether a particular software product is as much energetically efficient as possible, or at least more efficient than another, and to improve the environmental objectives of the software. For this reason, a Framework for Energy Efficiency Testing to Improve eNviromental Goals of the Software (FEETINGS) is presented in this paper. FEETINGS is composed of three main components: an ontology to provide precise definitions and harmonize the terminology related to software energy measurement; a process to guide researchers in carrying out the energy consumption measurements of the software, and a technological environment, which allows the capture, analysis and inter­ pretation of software energy consumption data. This paper also presents an example of the application of the FEETINGS, which aims to raise awareness of the energy consumed by the software in activities that we perform daily, such as writing a tweet or a Facebook post. As a result, we have been able to verify that FEETINGS allows us to carry out an analysis and measurement of software energy consumption to provide users with good practices, as using an emoji or a picture rather than a GIF. © 2001 Elsevier Science. All rights reserved.},
	language = {en},
	urldate = {2023-11-27},
	journal = {Sustainable Computing: Informatics and Systems},
	author = {Mancebo, Javier and Calero, Coral and Garcia, Felix and Moraga, Mª Angeles and Garcia-Rodriguez De Guzman, Ignacio},
	month = jun,
	year = {2021},
	pages = {100558},
}

@inproceedings{shenoy_green_2011,
	address = {Hyderabad, India},
	title = {Green software development model: {An} approach towards sustainable software development},
	isbn = {978-1-4577-1109-1 978-1-4577-1110-7 978-1-4577-1108-4},
	shorttitle = {Green software development model},
	url = {http://ieeexplore.ieee.org/document/6139638/},
	doi = {10.1109/INDCON.2011.6139638},
	language = {en},
	urldate = {2024-02-11},
	booktitle = {2011 {Annual} {IEEE} {India} {Conference}},
	publisher = {IEEE},
	author = {Shenoy, Sanath. S. and Eeratta, Raghavendra},
	month = dec,
	year = {2011},
	pages = {1--6},
}


\\ REQUIREMENTS


@article{subahi_bert-based_2023,
	title = {{BERT}-{Based} {Approach} for {Greening} {Software} {Requirements} {Engineering} {Through} {Non}-{Functional} {Requirements}},
	volume = {11},
	issn = {2169-3536},
	url = {https://ieeexplore.ieee.org/document/10256174/},
	doi = {10.1109/ACCESS.2023.3317798},
	abstract = {The incorporation of sustainability principles during the requirements engineering phase of the development life cycle constitutes greening software requirements. This incorporation can have a variety of effects on the software design employed in modern and cutting-edge information technology (IT) systems. When sustainability principles are incorporated into requirements engineering, software design priorities can change and address current design issues such as energy and resource consumption, modularity, maintainability, and adaptability. In contrast to other green approaches that consider sustainable development, there is a further need to investigate the relationship between software development and the relevant green principles of sustainability during the requirements engineering phase. We present a new mechanism for mapping software nonfunctional requirements (NFRs) to defined dimensions of green software sustainability, consisting of two mapping steps: 1) between NFRs and sustainability dimensions; and 2) between sustainability dimensions and two clusters of green IT aspects defined in this work. The overall architecture of the promising approach is based on the use of the Bidirectional Encoder Representations from Transformers (BERT) language model with an expanded dataset. We consider transfer learning and domainspecific fine-tuning capabilities for constructing and evaluating a model specifically tailored for developing a proof of concept of the greening software requirements engineering task, as language models have recently emerged as a potent technique in the field of software engineering, with numerous applications in code analysis, automated documentation, and code generation. In addition, we test the model’s performance using an extended version of the PROMISE\_exp dataset after adding a new binary classification column for categorizing sustainability dimensions into two defined clusters: Eco-technical and Socioeconomic, and having a selected domain expert label the raw data. The model’s efficiency is evaluated using four matrices—1) accuracy; 2) precision; 3) recall; and 4) F1 score—across a variety of epoch and batch sizes. Our numerical results demonstrate the viability of the approach in text classification tasks via performing well in mapping NFRs to software sustainability dimensions. This acts as a proof of concept for automating the sustainability measurement of software awareness at the early development stage. In addition, the results emphasize the importance of domain-specific fine-tuning and transfer learning for obtaining high performance in classification tasks in requirements engineering.},
	language = {en},
	urldate = {2023-11-16},
	journal = {IEEE Access},
	author = {Subahi, Ahmad F.},
	year = {2023},
	pages = {103001--103013},
}

@article{zhao_natural_2022,
	title = {Natural {Language} {Processing} for {Requirements} {Engineering}: {A} {Systematic} {Mapping} {Study}},
	volume = {54},
	issn = {0360-0300, 1557-7341},
	shorttitle = {Natural {Language} {Processing} for {Requirements} {Engineering}},
	url = {https://dl.acm.org/doi/10.1145/3444689},
	doi = {10.1145/3444689},
	abstract = {Natural Language Processing for Requirements Engineering (NLP4RE) is an area of research and development that seeks to apply natural language processing (NLP) techniques, tools, and resources to the requirements engineering (RE) process, to support human analysts to carry out various linguistic analysis tasks on textual requirements documents, such as detecting language issues, identifying key domain concepts, and establishing requirements traceability links. This article reports on a mapping study that surveys the landscape of NLP4RE research to provide a holistic understanding of the field. Following the guidance of systematic review, the mapping study is directed by five research questions, cutting across five aspects of NLP4RE research, concerning the state of the literature, the state of empirical research, the research focus, the state of tool development, and the usage of NLP technologies. Our main results are as follows: (i) we identify a total of 404 primary studies relevant to NLP4RE, which were published over the past 36 years and from 170 different venues; (ii) most of these studies (67.08\%) are solution proposals, assessed by a laboratory experiment or an example application, while only a small percentage (7\%) are assessed in industrial settings; (iii) a large proportion of the studies (42.70\%) focus on the requirements analysis phase, with quality defect detection as their central task and requirements specification as their commonly processed document type; (iv) 130 NLP4RE tools (i.e., RE specific NLP tools) are extracted from these studies, but only 17 of them (13.08\%) are available for download; (v) 231 different NLP technologies are also identified, comprising 140 NLP techniques, 66 NLP tools, and 25 NLP resources, but most of them—particularly those novel NLP techniques and specialized tools—are used infrequently; by contrast, commonly used NLP technologies are traditional analysis techniques (e.g., POS tagging and tokenization), general-purpose tools (e.g., Stanford CoreNLP and GATE) and generic language lexicons (WordNet and British National Corpus). The mapping study not only provides a collection of the literature in NLP4RE but also, more importantly, establishes a structure to frame the existing literature through categorization, synthesis and conceptualization of the main theoretical concepts and relationships that encompass both RE and NLP aspects. Our work thus produces a
              conceptual framework
              of NLP4RE. The framework is used to identify research gaps and directions, highlight technology transfer needs, and encourage more synergies between the RE community, the NLP one, and the software and systems practitioners. Our results can be used as a starting point to frame future studies according to a well-defined terminology and can be expanded as new technologies and novel solutions emerge.},
	language = {en},
	number = {3},
	urldate = {2023-11-16},
	journal = {ACM Computing Surveys},
	author = {Zhao, Liping and Alhoshan, Waad and Ferrari, Alessio and Letsholo, Keletso J. and Ajagbe, Muideen A. and Chioasca, Erol-Valeriu and Batista-Navarro, Riza T.},
	month = apr,
	year = {2022},
	pages = {1--41},
}

@inproceedings{quba_software_2021,
	address = {Amman, Jordan},
	title = {Software {Requirements} {Classification} using {Machine} {Learning} algorithm’s},
	isbn = {978-1-66542-870-5},
	url = {https://ieeexplore.ieee.org/document/9491688/},
	doi = {10.1109/ICIT52682.2021.9491688},
	abstract = {The world is growing and developing rapidly, and the demand for software has been increasing speedily, any software has many steps for building a program and all the steps are important for software requirements. Requirements classification can be applied manually, which requires great effort, time, cost and the accuracy may vary. Therefore, many previous researchv has been proposed to automate the classification process, but the automation process of the classification was not sufficient. In this study, we will propose a technique to automatically classify software requirements using machine learning to represent text data from software requirements specification and classify requirement to group Functional Requirement and Non-Functional Requirement. The experimented dataset in this study was the PROMISE\_exp, which includes labeled requirements. All the documents of software from the database were changed (cleaned) with a set of steps (normalization, extractions, selection any techniques that will be used. The BoW used SVM algorithm or KNN algorithm for classification. This study used data from the PROMISE\_exp to do the work, the information of the steps used to re-performed the classification, and the Measurement BoW, when using SVM and KNN algorithms the classification of requirements making can serve as a way and resources for another study. It can be seen that the use of BoW with SVM is better than use KNN algorithms with an average F-measure of all cases of 0.74. In future work we intend to improve to technique with make merge and change some algorithms as Logiest Regression to improve the Accuracy ( Precision) of our model.},
	language = {en},
	urldate = {2023-12-03},
	booktitle = {2021 {International} {Conference} on {Information} {Technology} ({ICIT})},
	publisher = {IEEE},
	author = {Quba, Gaith Y and Al Qaisi, Hadeel and Althunibat, Ahmad and AlZu'bi, Shadi},
	month = jul,
	year = {2021},
	pages = {685--690},
}

@article{perini_machine_2013,
	title = {A {Machine} {Learning} {Approach} to {Software} {Requirements} {Prioritization}},
	volume = {39},
	issn = {0098-5589, 1939-3520},
	url = {http://ieeexplore.ieee.org/document/6249686/},
	doi = {10.1109/TSE.2012.52},
	abstract = {Deciding which, among a set of requirements, are to be considered first and in which order is a strategic process in software development. This task is commonly referred to as requirements prioritization. This paper describes a requirements prioritization method called Case-Based Ranking (CBRank), which combines project’s stakeholders preferences with requirements ordering approximations computed through machine learning techniques, bringing promising advantages. First, the human effort to input preference information can be reduced, while preserving the accuracy of the final ranking estimates. Second, domain knowledge encoded as partial order relations defined over the requirement attributes can be exploited, thus supporting an adaptive elicitation process. The techniques CBRank rests on and the associated prioritization process are detailed. Empirical evaluations of properties of CBRank are performed on simulated data and compared with a state-of-the-art prioritization method, providing evidence of the method ability to support the management of the tradeoff between elicitation effort and ranking accuracy and to exploit domain knowledge. A case study on a real software project complements these experimental measurements. Finally, a positioning of CBRank with respect to state-of-the-art requirements prioritization methods is proposed, together with a discussion of benefits and limits of the method.},
	language = {en},
	number = {4},
	urldate = {2023-12-03},
	journal = {IEEE Transactions on Software Engineering},
	author = {Perini, Anna and Susi, Angelo and Avesani, Paolo},
	month = apr,
	year = {2013},
	pages = {445--461},
}

@inproceedings{navarro-almanza_towards_2017,
	address = {Mérida},
	title = {Towards {Supporting} {Software} {Engineering} {Using} {Deep} {Learning}: {A} {Case} of {Software} {Requirements} {Classification}},
	isbn = {978-1-5386-3956-6},
	shorttitle = {Towards {Supporting} {Software} {Engineering} {Using} {Deep} {Learning}},
	url = {https://ieeexplore.ieee.org/document/8337942/},
	doi = {10.1109/CONISOFT.2017.00021},
	abstract = {Software Requirements are the basis of high-quality software development process, each step is related to SR, these represent the needs and expectations of the software in a very detailed form. The software requirement classiﬁcation (SRC) task requires a lot of human effort, specially when there are huge of requirements, therefore, the automation of SRC have been addressed using Natural Language Processing (NLP) and Information Retrieval (IR) techniques, however, generally requires human effort to analyze and create features from corpus (set of requirements). In this work, we propose to use Deep Learning (DL) to classify software requirements without labor intensive feature engineering. The model that we propose is based on Convolutional Neural Network (CNN) that has been state of art in other natural language related tasks. To evaluate our proposed model, PROMISE corpus was used, contains a set of labeled requirements in functional and 11 different categories of nonfunctional requirements. We achieve promising results on SRC using CNN even without handcrafted features.},
	language = {en},
	urldate = {2023-12-03},
	booktitle = {2017 5th {International} {Conference} in {Software} {Engineering} {Research} and {Innovation} ({CONISOFT})},
	publisher = {IEEE},
	author = {Navarro-Almanza, Raul and Juarez-Ramirez, Reyes and Licea, Guillermo},
	month = oct,
	year = {2017},
	pages = {116--120},
}

@inproceedings{riaz_automatic_2019,
	address = {Cambridge, United Kingdom},
	title = {Automatic {Detection} of {Ambiguous} {Software} {Requirements}: {An} {Insight}},
	isbn = {978-1-72813-430-7},
	shorttitle = {Automatic {Detection} of {Ambiguous} {Software} {Requirements}},
	url = {https://ieeexplore.ieee.org/document/8714682/},
	doi = {10.1109/INFOMAN.2019.8714682},
	abstract = {Requirements Engineering is one of the most important phases of the software development lifecycle. The success of the whole software project depends upon the quality of the requirements. But as we know that mostly the software requirements are stated and documented in the natural language. The requirements written in natural language can be ambiguous and inconsistent. These ambiguities and inconsistencies can lead to misinterpretations and wrong implementations in design and development phase. To address these issues a number of approaches, tools and techniques have been proposed for the automatic detection of natural language ambiguities form software requirement documents. However, to the best of our knowledge, there is very little work done to compare and analyze the differences between these tools and techniques. In this paper, we presented a state of art survey of the currently available tools and techniques for the automatic detection of natural language ambiguities from software requirements. We also focused on figuring out the popularity of different tools and techniques on the basis of citations. This research will help the practitioners and researchers to get the latest insights in the above-mentioned context.},
	language = {en},
	urldate = {2023-12-03},
	booktitle = {2019 5th {International} {Conference} on {Information} {Management} ({ICIM})},
	publisher = {IEEE},
	author = {Riaz, Muhammad Qasim and Butt, Wasi Haider and Rehman, Saad},
	month = mar,
	year = {2019},
	pages = {1--6},
}

@inproceedings{sharma_agile_2019,
	address = {Dubai, United Arab Emirates},
	title = {Agile {Release} {Planning} {Using} {Natural} {Language} {Processing} {Algorithm}},
	isbn = {978-1-5386-9346-9},
	url = {https://ieeexplore.ieee.org/document/8701252/},
	doi = {10.1109/AICAI.2019.8701252},
	abstract = {Abstract: once the requirement is gathered in agile, it is broken down into smaller pre-defined format called user stories. These user stories are then scoped in various sprint releases and delivered accordingly. Release planning in Agile becomes challenging when the number of user stories goes up in hundreds. In such scenarios it is very difficult to manually identify similar user stories and package them together into a release. Hence, this paper suggests application of natural language processing algorithms for identifying similar user stories and then scoping them into a release This paper takes the approach to build a word corpus for every project release identified in the project and then to convert the provided user stories into a vector of string using Java utility for calculating top 3 most occurring words from the given project corpus in a user story. Once all the user stories are represented as vector array then by using RV coefficient NLP algorithm the user stories are clustered into various releases of the software project. Using the proposed approach, the release planning for large and complex software engineering projects can be simplified resulting into efficient planning in less time. The automated commercial tools like JIRA and Rally can be enhanced to include suggested algorithms for managing release planning in Agile.},
	language = {en},
	urldate = {2023-12-03},
	booktitle = {2019 {Amity} {International} {Conference} on {Artificial} {Intelligence} ({AICAI})},
	publisher = {IEEE},
	author = {Sharma, Sarika and Kumar, Deepak},
	month = feb,
	year = {2019},
	pages = {934--938},
}

@article{raharjana_user_2021,
	title = {User {Stories} and {Natural} {Language} {Processing}: {A} {Systematic} {Literature} {Review}},
	volume = {9},
	issn = {2169-3536},
	shorttitle = {User {Stories} and {Natural} {Language} {Processing}},
	url = {https://ieeexplore.ieee.org/document/9393933/},
	doi = {10.1109/ACCESS.2021.3070606},
	abstract = {Context: User stories have been widely accepted as artifacts to capture the user requirements in agile software development. They are short pieces of texts in a semi-structured format that express requirements. Natural language processing (NLP) techniques offer a potential advantage in user story applications. Objective: Conduct a systematic literature review to capture the current state-of-the-art of NLP research on user stories. Method: The search strategy is used to obtain relevant papers from SCOPUS, ScienceDirect, IEEE Xplore, ACM Digital Library, SpringerLink, and Google Scholar. Inclusion and exclusion criteria are applied to ﬁlter the search results. We also use the forward and backward snowballing techniques to obtain more comprehensive results. Results: The search results identiﬁed 718 papers published between January 2009 to December 2020. After applying the inclusion/exclusion criteria and the snowballing technique, we identiﬁed 38 primary studies that discuss NLP techniques in user stories. Most studies used NLP techniques to extract aspects of who, what, and why from user stories. The purpose of NLP studies in user stories is broad, ranging from discovering defects, generating software artifacts, identifying the key abstraction of user stories, and tracing links between model and user stories. Conclusion: NLP can help system analysts manage user stories. Implementing NLP in user stories has many opportunities and challenges. Considering the exploration of NLP techniques and rigorous evaluation methods is required to obtain quality research. As with NLP research in general, the ability to understand a sentence’s context continues to be a challenge.},
	language = {en},
	urldate = {2023-12-03},
	journal = {IEEE Access},
	author = {Raharjana, Indra Kharisma and Siahaan, Daniel and Fatichah, Chastine},
	year = {2021},
	pages = {53811--53826},
}

@inproceedings{saidani_can_2021,
	address = {Virtual, Online},
	title = {Can {Machine} {Learning} {Tools} {Support} the {Identification} of {Sustainable} {Design} {Leads} {From} {Product} {Reviews}? {Opportunities} and {Challenges}},
	isbn = {978-0-7918-8538-3},
	shorttitle = {Can {Machine} {Learning} {Tools} {Support} the {Identification} of {Sustainable} {Design} {Leads} {From} {Product} {Reviews}?},
	url = {https://asmedigitalcollection.asme.org/IDETC-CIE/proceedings/IDETC-CIE2021/85383/V03AT03A005/1128313},
	doi = {10.1115/DETC2021-70613},
	abstract = {The increasing number of product reviews posted online is a gold mine for designers to know better about the products they develop, by capturing the voice of customers, and to improve these products accordingly. In the meantime, product design and development have an essential role in creating a more sustainable future. With the recent advance of artificial intelligence techniques in the field of natural language processing, this research aims to develop an integrated machine learning solution to obtain sustainable design insights from online product reviews automatically. In this paper, the opportunities and challenges offered by existing frameworks –including Python libraries, packages, as well as state-of-the-art algorithms like BERT – are discussed, illustrated, and positioned along an ad hoc machine learning process. This contribution discusses the opportunities to reach and the challenges to address for building a machine learning pipeline, in order to get insights from product reviews to design more sustainable products, including the five following stages, from the identification of sustainability-related reviews to the interpretation of sustainable design leads: data collection, data formatting, model training, model evaluation, and model deployment. Examples of sustainable design insights that can be produced out of product review mining and processing are given. Finally, promising lines for future research in the field are provided, including case studies putting in parallel standard products with their sustainable alternatives, to compare the features valued by customers and to generate in fine relevant sustainable design leads.},
	language = {en},
	urldate = {2023-12-03},
	booktitle = {Volume {3A}: 47th {Design} {Automation} {Conference} ({DAC})},
	publisher = {American Society of Mechanical Engineers},
	author = {Saidani, Michael and Kim, Harrison and Yannou, Bernard},
	month = aug,
	year = {2021},
	pages = {V03AT03A005},
}


\\ ANALYSIS DESIGN

@article{breitbach_computation_nodate,
	title = {Computation {Offloading} for {Fast} and {Energy}-{Efficient} {Edge} {Computing}},
	language = {en},
	author = {Breitbach, Martin},
    month = feb,
	year = {2022},
}

@article{cozad_learning_2014,
	title = {Learning surrogate models for simulation‐based optimization},
	volume = {60},
	issn = {0001-1541, 1547-5905},
	url = {https://aiche.onlinelibrary.wiley.com/doi/10.1002/aic.14418},
	doi = {10.1002/aic.14418},
	abstract = {A central problem in modeling, namely that of learning an algebraic model from data obtained from simulations or experiments is addressed. A methodology that uses a small number of simulations or experiments to learn models that are as accurate and as simple as possible is proposed. The approach begins by building a low‐complexity surrogate model. The model is built using a best subset technique that leverages an integer programming formulation to allow for the efficient consideration of a large number of possible functional components in the model. The model is then improved systematically through the use of derivative‐free optimization solvers to adaptively sample new simulation or experimental points. Automated learning of algebraic models for optimization (ALAMO), the computational implementation of the proposed methodology, along with examples and extensive computational comparisons between ALAMO and a variety of machine learning techniques, including Latin hypercube sampling, simple least‐squares regression, and the lasso is described. © 2014 American Institute of Chemical Engineers
              AIChE J
              , 60: 2211–2227, 2014},
	language = {en},
	number = {6},
	urldate = {2023-12-01},
	journal = {AIChE Journal},
	author = {Cozad, Alison and Sahinidis, Nikolaos V. and Miller, David C.},
	month = jun,
	year = {2014},
	pages = {2211--2227},
}

@inproceedings{nawrocki_adaptive_2020,
	address = {Melbourne, Australia},
	title = {Adaptive context-aware energy optimization for services on mobile devices with use of machine learning considering security aspects},
	isbn = {978-1-72816-095-5},
	url = {https://ieeexplore.ieee.org/document/9139636/},
	doi = {10.1109/CCGrid49817.2020.00-19},
	abstract = {In this paper we present an original adaptive task scheduling system, which optimizes the energy consumption of mobile devices using machine learning mechanisms and context information. The system learns how to allocate resources appropriately: how to schedule services/tasks optimally between the device and the cloud, which is especially important in mobile systems. Decisions are made taking the context into account (e.g. network connection type, location, potential time and cost of executing the application or service). In this study, a supervised learning agent architecture and service selection algorithm are proposed to solve this problem. Adaptation is performed online, on a mobile device. Information about the context, task description, the decision made and its results such as power consumption are stored and constitute training data for a supervised learning algorithm, which updates the knowledge used to determine the optimal location for the execution of a given type of task. To verify the solution proposed, appropriate software has been developed and a series of experiments have been conducted. Results show that due to the experience gathered and the learning process performed, the decision module has consequently become more efﬁcient in assigning the task to either the mobile device or cloud resources. In face of presented improvements, the security issues inherent within the context of mobile application and cloud computing are further discussed. As threats associated with mobile data ofﬂoading are a serious concern, often preventing the utilization of cloud services, we propose a more security focused approach for our solution, preferably without hindering the performance.},
	language = {en},
	urldate = {2023-12-01},
	booktitle = {2020 20th {IEEE}/{ACM} {International} {Symposium} on {Cluster}, {Cloud} and {Internet} {Computing} ({CCGRID})},
	publisher = {IEEE},
	author = {Nawrocki, Piotr and Sniezynski, Bartlomiej and Kolodziej, Joanna and Szynkiewicz, Pawel},
	month = may,
	year = {2020},
	pages = {708--717},
}

@article{junior_context-sensitive_2019,
	title = {A context-sensitive offloading system using machine-learning classification algorithms for mobile cloud environment},
	volume = {90},
	issn = {0167739X},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167739X17326729},
	doi = {10.1016/j.future.2018.08.026},
	abstract = {Computational offloading in Mobile Cloud Computing (MCC) has attracted attention due to benefits in energy saving and improved mobile application performance. Nevertheless, this technique underperforms if the offloading decision ignores contextual information. While recent studies have highlighted the use of contextual information to improve the computational offloading decision, there still remain challenges regarding the dynamic nature of the MCC environment. Most solutions design a single reasoner for the offloading decision and do not know how accurate and precise this technique is, so that when applied in real-world environments it can contribute to inaccurate decisions and consequently the low performance of the overall system. Thus, this paper proposes a Context-Sensitive Offloading System (CSOS) that takes advantage of the main machine-learning reasoning techniques and robust profiling system to provide offloading decisions with high levels of accuracy. We first evaluate the main classification algorithms under our database and the results show that JRIP and J48 classifiers achieves 95\% accuracy. Secondly, we develop and evaluate our system under controlled and real scenarios, where context information changes from one experiment to another. Under these conditions, CSOS makes correct decisions as well as ensuring performance gains and energy efficiency.},
	language = {en},
	urldate = {2023-12-01},
	journal = {Future Generation Computer Systems},
	author = {Junior, Warley and Oliveira, Eduardo and Santos, Albertinin and Dias, Kelvin},
	month = jan,
	year = {2019},
	pages = {503--520},
}

@article{alizadeh_managing_2020,
	title = {Managing computational complexity using surrogate models: a critical review},
	volume = {31},
	issn = {0934-9839, 1435-6066},
	shorttitle = {Managing computational complexity using surrogate models},
	url = {http://link.springer.com/10.1007/s00163-020-00336-7},
	doi = {10.1007/s00163-020-00336-7},
	abstract = {In simulation-based realization of complex systems, we are forced to address the issue of computational complexity. One critical issue that must be addressed is the approximation of reality using surrogate models to replace expensive simulation models of engineering problems. In this paper, we critically review over 200 papers. We find that a framework for selecting appropriate surrogate modeling methods for a given function with specific requirements has been lacking. Having such a framework for surrogate model users, specifically practitioners in industry, is very important because there is very limited information about the performance of different models before applying them on the problem. Our contribution in this paper is to address this gap by creating practical guidance based on a trade-off among three main drivers, namely, size (how much information is necessary to compute the surrogate model), accuracy (how accurate the surrogate model must be) and computational time (how much time is required for the surrogate modeling process). Using the proposed guidance a huge amount of time is saved by avoiding time-consuming comparisons before selecting the appropriate surrogate model. To make this contribution, we review the state-of-the-art surrogate modeling literature to answer the following three questions: (1) What are the main classes of the design of experiment (DOE) methods, surrogate modeling methods and model-fitting methods based on the requirements of size, computational time, and accuracy? (2) Which surrogate modeling method is suitable based on the critical characteristics of the requirements of size, computational time and accuracy? (3) Which DOE is suitable based on the critical characteristics of the requirements of size, computational time and accuracy? Based on these three characteristics, we find six different qualitative categories for the surrogate models through a critical evaluation of the literature. These categories provide a framework for selecting an efficient surrogate modeling process to assist those who wish to select more appropriate surrogate modeling techniques for a given function. It is also summarized in Table 4 and Figs. 2, 3. MARS, response surface models, and kriging are more appropriate for large problems, acquiring less computation time and high accuracy, respectively. Also, Latin Hypercube, fractional factorial designs and D-Optimal designs are appropriate experimental designs. Our contribution is to propose a qualitative evaluation and a mental model which is based on quantitative results and findings of authors in the published literature. The value of such a framework is in providing practical guide for researchers and practitioners in industry to choose the most appropriate surrogate model based on incomplete information about an engineering design problem. Another contribution is to use three drivers, namely, computational time, accuracy, and problem size instead of using a single measure that authors generally use in the published literature.},
	language = {en},
	number = {3},
	urldate = {2023-12-05},
	journal = {Research in Engineering Design},
	author = {Alizadeh, Reza and Allen, Janet K. and Mistree, Farrokh},
	month = jul,
	year = {2020},
	pages = {275--298},
}


// TESTING ///////////////////////


@inproceedings{shamshiri_how_2018,
	address = {Vasteras},
	title = {How {Do} {Automatically} {Generated} {Unit} {Tests} {Influence} {Software} {Maintenance}?},
	isbn = {978-1-5386-5012-7},
	url = {https://ieeexplore.ieee.org/document/8367053/},
	doi = {10.1109/ICST.2018.00033},
	abstract = {Generating unit tests automatically saves time over writing tests manually and can lead to higher code coverage. However, automatically generated tests are usually not based on realistic scenarios, and are therefore generally considered to be less readable. This places a question mark over their practical value: Every time a test fails, a developer has to decide whether this failure has revealed a regression fault in the program under test, or whether the test itself needs to be updated. Does the fact that automatically generated tests are harder to read outweigh the time-savings gained by their automated generation, and render them more of a hindrance than a help for software maintenance? In order to answer this question, we performed an empirical study in which participants were presented with an automatically generated or manually written failing test, and were asked to identify and fix the cause of the failure. Our experiment and two replications resulted in a total of 150 data points based on 75 participants. Whilst maintenance activities take longer when working with automatically generated tests, we found developers to be equally effective with manually written and automatically generated tests. This has implications on how automated test generation is best used in practice, and it indicates a need for research into the generation of more realistic tests.},
	language = {en},
	urldate = {2023-11-20},
	booktitle = {2018 {IEEE} 11th {International} {Conference} on {Software} {Testing}, {Verification} and {Validation} ({ICST})},
	publisher = {IEEE},
	author = {Shamshiri, Sina and Rojas, Jose Miguel and Galeotti, Juan Pablo and Walkinshaw, Neil and Fraser, Gordon},
	month = apr,
	year = {2018},
	pages = {250--261},
}

@inproceedings{hourani_impact_2019,
	address = {Amman, Jordan},
	title = {The {Impact} of {Artificial} {Intelligence} on {Software} {Testing}},
	isbn = {978-1-5386-7942-5},
	url = {https://ieeexplore.ieee.org/document/8717439/},
	doi = {10.1109/JEEIT.2019.8717439},
	abstract = {Artificial Intelligence (AI) plays an important role in our life and touch base most of our surrounding applications and systems. A huge amounts of data are created every day from many different sources that need to be monitored and analyzed properly and report results and take actions. A more complex software applications have been built, time is becoming a critical factor to release applications that must be fully tested and comply with Business Requirements. AI plays a key role in Software Testing and can get more accurate results and saves time. This paper discuss the Artificial Intelligence key pillars that can be used in Software Testing. It also open a window on how the future will look like in terms of Artificial Intelligence and the Software Testing. The results show that AI can achieve better results in Software Testing and AI-driven testing will lead the new era of the quality assurance (QA) work in the near future. AI Software Testing will reduce time to market and will increase the efficiency of the organization to produce more sophisticated software and will create smarter automated testing.},
	language = {en},
	urldate = {2023-11-21},
	booktitle = {2019 {IEEE} {Jordan} {International} {Joint} {Conference} on {Electrical} {Engineering} and {Information} {Technology} ({JEEIT})},
	publisher = {IEEE},
	author = {Hourani, Hussam and Hammad, Ahmad and Lafi, Mohammad},
	month = apr,
	year = {2019},
	pages = {565--570},
}

@article{durelli_machine_2019,
	title = {Machine {Learning} {Applied} to {Software} {Testing}: {A} {Systematic} {Mapping} {Study}},
	volume = {68},
	issn = {0018-9529, 1558-1721},
	shorttitle = {Machine {Learning} {Applied} to {Software} {Testing}},
	url = {https://ieeexplore.ieee.org/document/8638573/},
	doi = {10.1109/TR.2019.2892517},
	abstract = {Objective: We set out to review the state-of-the-art of how ML has been explored to automate and streamline software testing and provide an overview of the research at the intersection of these two ﬁelds by conducting a systematic mapping study.
Method: We selected 48 primary studies. These selected studies were then categorized according study type, testing activity, and ML algorithm employed to automate the testing activity.
Results: The results highlight the most widely used ML algorithms and identify several avenues for future research. We found that ML algorithms have been used mainly for test case generation, reﬁnement, and evaluation. Also, ML has been used to evaluate test oracle construction and to predict the cost of testing-related activities.
Conclusions: The results of our study outline the ML algorithms that are most commonly used to automate software testing activities, helping researchers to understand the current state of research concerning ML applied to software testing. We also found that there is a need for better empirical studies examining how ML algorithms have been used to automate software testing activities.},
	language = {en},
	number = {3},
	urldate = {2023-12-01},
	journal = {IEEE Transactions on Reliability},
	author = {Durelli, Vinicius H. S. and Durelli, Rafael S. and Borges, Simone S. and Endo, Andre T. and Eler, Marcelo M. and Dias, Diego R. C. and Guimaraes, Marcelo P.},
	month = sep,
	year = {2019},
	pages = {1189--1212},
}

@inproceedings{wen_enhancing_2019,
	address = {San Diego, CA},
	title = {Enhancing {Symbolic} {Execution} by {Machine} {Learning} {Based} {Solver} {Selection}},
	isbn = {978-1-891562-58-7},
	url = {https://www.ndss-symposium.org/wp-content/uploads/bar2019_80_Wen_paper.pdf},
	doi = {10.14722/bar.2019.23080},
	abstract = {Constraint solving creates a serious performance bottleneck in symbolic execution. Examining a plethora of SMT solvers with diverse capabilities, we address the following research questions: How can the performance of symbolic execution improve if it can pick a priori the best solver for a given path constraint? How can such a prediction oracle be practically implemented? In this work, we ﬁrst deﬁne the solver selection problem in symbolic execution and its evaluation metrics, and perform a preliminary study to gauge potential performance improvement through solver selection. We then present the design and implementation of Path Constraint Classiﬁer (PCC), a machine learning based meta-solver that aims to reduce overall constraint solving latency by dynamically selecting a solver per query. The use of using machine learning seems straightforward, yet surprisingly underexplored; one main technical challenge is how to avoid excessive overhead introduced by feature extraction. We address this challenge by taking advantage of the structural characteristics of symbolic execution. Our experiments conﬁrm that the overall solver time can be reduced by 10.3\% in the KLEE dataset and 46\% in the benchmark dataset, while the solver prediction procedure only accounts for 2\% to 10\% of overall solving time.},
	language = {en},
	urldate = {2023-12-02},
	booktitle = {Proceedings 2019 {Workshop} on {Binary} {Analysis} {Research}},
	publisher = {Internet Society},
	author = {Wen, Sheng-Han and Mow, Wei-Loon and Chen, Wei-Ning and Wang, Chien-Yuan and Hsiao, Hsu-Chun},
	year = {2019},
}

@inproceedings{kahles_automating_2019,
	address = {Xi'an, China},
	title = {Automating {Root} {Cause} {Analysis} via {Machine} {Learning} in {Agile} {Software} {Testing} {Environments}},
	isbn = {978-1-72811-736-2},
	url = {https://ieeexplore.ieee.org/document/8730163/},
	doi = {10.1109/ICST.2019.00047},
	abstract = {We apply machine learning to automate the root cause analysis in agile software testing environments. In particular, we extract relevant features from raw log data after interviewing testing engineers (human experts). Initial efforts are put into clustering the unlabeled data, and despite obtaining weak correlations between several clusters and failure root causes, the vagueness in the rest of the clusters leads to the consideration of labeling. A new round of interviews with the testing engineers leads to the deﬁnition of ﬁve ground-truth categories. Using manually labeled data, we train artiﬁcial neural networks that either classify the data or pre-process it for clustering. The resulting method achieves an accuracy of 88.9\%. The methodology of this paper serves as a prototype or baseline approach for the extraction of expert knowledge and its adaptation to machine learning techniques for root cause analysis in agile environments.},
	language = {en},
	urldate = {2023-12-03},
	booktitle = {2019 12th {IEEE} {Conference} on {Software} {Testing}, {Validation} and {Verification} ({ICST})},
	publisher = {IEEE},
	author = {Kahles, Julen and Torronen, Juha and Huuhtanen, Timo and Jung, Alexander},
	month = apr,
	year = {2019},
	pages = {379--390},
}

@inproceedings{du_deeplog_2017,
	address = {Dallas Texas USA},
	title = {{DeepLog}: {Anomaly} {Detection} and {Diagnosis} from {System} {Logs} through {Deep} {Learning}},
	isbn = {978-1-4503-4946-8},
	shorttitle = {{DeepLog}},
	url = {https://dl.acm.org/doi/10.1145/3133956.3134015},
	doi = {10.1145/3133956.3134015},
	abstract = {Anomaly detection is a critical step towards building a secure and trustworthy system. e primary purpose of a system log is to record system states and signi cant events at various critical points to help debug system failures and perform root cause analysis. Such log data is universally available in nearly all computer systems. Log data is an important and valuable resource for understanding system status and performance issues; therefore, the various system logs are naturally excellent source of information for online monitoring and anomaly detection. We propose DeepLog, a deep neural network model utilizing Long Short-Term Memory (LSTM), to model a system log as a natural language sequence. is allows DeepLog to automatically learn log pa erns from normal execution, and detect anomalies when log pa erns deviate from the model trained from log data under normal execution. In addition, we demonstrate how to incrementally update the DeepLog model in an online fashion so that it can adapt to new log pa erns over time. Furthermore, DeepLog constructs work ows from the underlying system log so that once an anomaly is detected, users can diagnose the detected anomaly and perform root cause analysis e ectively. Extensive experimental evaluations over large log data have shown that DeepLog has outperformed other existing log-based anomaly detection methods based on traditional data mining methodologies.},
	language = {en},
	urldate = {2023-12-07},
	booktitle = {Proceedings of the 2017 {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {ACM},
	author = {Du, Min and Li, Feifei and Zheng, Guineng and Srikumar, Vivek},
	month = oct,
	year = {2017},
	pages = {1285--1298},
}

\\ DEVELOPMENT \\\\\\\\\\\\\\\\\\\\\


@article{sandhu_software_2021,
	title = {Software reuse analytics using integrated random forest and gradient boosting machine learning algorithm},
	volume = {51},
	issn = {1097-024X},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/spe.2921},
	doi = {10.1002/spe.2921},
	abstract = {The term Cleaner Production (CP) for Production Companies is contemplated as influential to get sustainable production. CP mainly deals with three R's that is, reuse, reduce, and recycle. For software enterprise, the software reuse plays a pivotal role. Software reuse is a process of producing new products or software from the existing software by updating it. To extract useful information from the existing software data mining comes into light. The algorithms used for software reuse face issues related to maintenance cost, accuracy, and performance. Also, the currently used algorithm does not give accurate results on whether the component of software can be reused. Machine Learning gives the best results to predicate if the given software component is reusable or not. This paper introduces an integrated Random Forest and Gradient Boosting Machine Learning Algorithm (RFGBM) which test the reusability of the given software code considering the object-oriented parameters such as cohesion, coupling, cyclomatic complexity, bugs, number of children, and depth inheritance tree. Further, the proposed algorithm is compared with J48, AdaBoostM1, LogitBoost, Part, One R, LMT, JRip, DecisionStump algorithms. Performance metrices like accuracy, error rate, Relative Absolute Error, and Mean Absolute Error are improved using RFGBM. This algorithm also utilizes data preprocessing with the help of an unsupervised filter to remove the missing value for efficiency improvement. Proposed algorithm outperforms existing in term of performance parameters.},
	language = {en},
	number = {4},
	urldate = {2023-11-21},
	journal = {Software: Practice and Experience},
	author = {Sandhu, Amandeep Kaur and Batth, Ranbir Singh},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/spe.2921},
	keywords = {AdaBoostM1, confusion matrix, DecisionStump, gradient boosting machine, J48, JRip, LMT, LogitBoost, one R, part, random forest, software metrics, software reuse},
	pages = {735--747},
}

@article{michanan_greenc5_2017,
	title = {{GreenC5}: {An} adaptive, energy-aware collection for green software development},
	volume = {13},
	issn = {22105379},
	shorttitle = {{GreenC5}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2210537916300403},
	doi = {10.1016/j.suscom.2016.11.004},
	language = {en},
	urldate = {2023-11-21},
	journal = {Sustainable Computing: Informatics and Systems},
	author = {Michanan, Junya and Dewri, Rinku and Rutherford, Matthew J.},
	month = mar,
	year = {2017},
	pages = {42--60},
}

@inproceedings{kumar_energy-efficient_2020,
	address = {New Orleans, LA, USA},
	title = {Energy-{Efficient} {Machine} {Learning} on the {Edges}},
	isbn = {978-1-72817-445-7},
	url = {https://ieeexplore.ieee.org/document/9150337/},
	doi = {10.1109/IPDPSW50202.2020.00153},
	abstract = {Machine learning-based software is vital for future Internet of Things (IoT) applications and Connected and Autonomous Vehicles (CAVs) as it provides the core value of these services by leveraging the enormous amount of data collected on the edge. These services utilize various machine learning models which make it computationally intensive on the edges. There has been a lot of work to make the hardware efﬁcient. No matter how efﬁcient is the hardware, an inefﬁcient machine learning model can account for high energy consumption and overheating problem. However, there are very few tools available that can help software developers or researchers to make the machine learning models energy efﬁcient.},
	language = {en},
	urldate = {2023-12-01},
	booktitle = {2020 {IEEE} {International} {Parallel} and {Distributed} {Processing} {Symposium} {Workshops} ({IPDPSW})},
	publisher = {IEEE},
	author = {Kumar, Mohit and Zhang, Xingzhou and Liu, Liangkai and Wang, Yifan and Shi, Weisong},
	month = may,
	year = {2020},
	pages = {912--921},
}

@article{alvi_mlee_2021,
	title = {{MLEE}: {Method} {Level} {Energy} {Estimation} — {A} machine learning approach},
	volume = {32},
	issn = {22105379},
	shorttitle = {{MLEE}},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2210537921000822},
	doi = {10.1016/j.suscom.2021.100594},
	abstract = {Battery life is one of the main concerns for today’s mobile users. Due to an imbalance in demand and supply of energy in mobile devices, the burden to make battery last longer upon each charge has shifted towards application developers, who, in turn attempt to create energy efficient applications. However, mobile developers lack the tools to detect energy consumption hot-spots in their code. We aim to provide developers with a technique that helps them to precisely locate energy hot-spots at the method-level. In this paper we present MLEE, a novel approach for estimating energy consumption of methods. MLEE uses machine learning models to predict the energy consumption at method-level using software metrics as features. We use the Snapdragon power profiler to measure the energy consumption of applications using the shortest time interval to develop a method-level energy dataset for training machine learning prediction models. We demonstrate that several structural metrics of methods are highly co-related with energy consumption. Thereafter we use these features to predict the energy consumption of methods using linear regression, random forest and decision tree with an average mean-absolute-error of 2.6  −2 J.},
	language = {en},
	urldate = {2023-12-01},
	journal = {Sustainable Computing: Informatics and Systems},
	author = {Alvi, Hamza Mustafa and Majeed, Hammad and Mujtaba, Hasan and Beg, Mirza Omer},
	month = dec,
	year = {2021},
	pages = {100594},
}

@article{aggarwal_power_nodate,
	title = {The {Power} of {System} {Call} {Traces}: {Predicting} the {Software} {Energy} {Consumption} {Impact} of {Changes}},
	abstract = {Battery is a critical resource for smartphones. Software developers as the builders and maintainers of applications, are responsible for updating and deploying energy efﬁcient applications to end users. Unfortunately, the impact of software change on energy consumption is still unclear. Estimation based on software metrics has proved difﬁcult. As energy consumption proﬁling requires special infrastructure, developers have difﬁculty assessing the impact of their actions on energy consumption. System calls are the interface between applications and the OS kernel and provide insight into how software utilizes hardware and software resources. As proﬁling system calls requires no specialized infrastructure, unlike energy consumption, it is much easier for the developers to track changes to system calls. Thus we relate software change to energy consumption by tracing the changes in an application’s pattern of system call invocations. We ﬁnd that signiﬁcant changes to system call proﬁles often induce signiﬁcant changes in energy consumption.},
	language = {en},
	author = {Aggarwal, Karan and Zhang, Chenlei and Campbell, Joshua Charles and Hindle, Abram and Stroulia, Eleni},
}

@article{kaur_machine_2023,
	title = {Machine learning based {Software} {Fault} {Prediction} models},
	volume = {9},
	issn = {2405-609X},
	url = {https://kijoms.uokerbala.edu.iq/home/vol9/iss2/9},
	doi = {10.33640/2405-609X.3297},
	abstract = {The study aims to identify soft-computing-based software fault prediction models that assist in resolving issues related to the quality, reliability, and cost of the software projects. It proposes models for implementation of software fault prediction using decision-tree regression and the K-nearest neighbor technique of machine learning. The proposed models have been designed and implemented in Python using designed metric suites as input, and the predicted-faults as output, for the real-time, wider dataset from the Promise repository. By comparing the prediction and validation results of the proposed models for the same dataset, it has been concluded that the decision-tree regression-based fault prediction model has the best performance with values of MMRE, RMSE, and accuracy of 0.0000204, 3.54, and 99.37, respectively.},
	language = {en},
	number = {2},
	urldate = {2023-12-01},
	journal = {Karbala International Journal of Modern Science},
	author = {Kaur, Gurmeet and Pruthi, Jyoti and Gandhi, Parul},
	month = apr,
	year = {2023},
}

@inproceedings{romansky_deep_2017,
	address = {Shanghai},
	title = {Deep {Green}: {Modelling} {Time}-{Series} of {Software} {Energy} {Consumption}},
	isbn = {978-1-5386-0992-7},
	shorttitle = {Deep {Green}},
	url = {http://ieeexplore.ieee.org/document/8094428/},
	doi = {10.1109/ICSME.2017.79},
	abstract = {Inefﬁcient mobile software kills battery life. Yet, developers lack the tools necessary to detect and solve energy bugs in software. In addition, developers are usually tasked with the creation of software features and triaging existing bugs. This means that most developers do not have the time or resources to research, build, or employ energy debugging tools.},
	language = {en},
	urldate = {2023-12-01},
	booktitle = {2017 {IEEE} {International} {Conference} on {Software} {Maintenance} and {Evolution} ({ICSME})},
	publisher = {IEEE},
	author = {Romansky, Stephen and Borle, Neil C. and Chowdhury, Shaiful and Hindle, Abram and Greiner, Russ},
	month = sep,
	year = {2017},
	pages = {273--283},
}

@inproceedings{wangoo_artificial_2018,
	address = {Greater Noida, India},
	title = {Artificial {Intelligence} {Techniques} in {Software} {Engineering} for {Automated} {Software} {Reuse} and {Design}},
	isbn = {978-1-5386-6947-1},
	url = {https://ieeexplore.ieee.org/document/8777584/},
	doi = {10.1109/CCAA.2018.8777584},
	abstract = {Mining of software engineering data have proved successful for reusability of components in software development. Artificial Intelligence improves a large application domain of software engineering activities. Intelligent knowledge discovery integrates Artificial Intelligence with Data Mining for intelligent computing of software engineering tasks. The integration of artificial intelligence with data mining for supporting software engineering applications leads to Software Intelligence. This paper analyzes three artificial intelligence techniques that uses data mining, business intelligence, machine learning for promoting automated software reuse for software construction and overall software development. The business intelligence tools are used for intelligent knowledge discovery of code that will be used for reusability of applications and components. An analysis of several AI techniques in software reuse domain of software engineering is discussed for automated software reuse and identification of potential research prospects in the field.},
	language = {en},
	urldate = {2023-12-07},
	booktitle = {2018 4th {International} {Conference} on {Computing} {Communication} and {Automation} ({ICCCA})},
	publisher = {IEEE},
	author = {Wangoo, Divanshi Priyadarshni},
	month = dec,
	year = {2018},
	pages = {1--4},
}


\\ DEPLOYMENT \\\\\\\\\\\\\\\

@inproceedings{feller_energy-aware_2011,
	address = {Lyon, France},
	title = {Energy-{Aware} {Ant} {Colony} {Based} {Workload} {Placement} in {Clouds}},
	isbn = {978-1-4577-1904-2},
	url = {http://ieeexplore.ieee.org/document/6076495/},
	doi = {10.1109/Grid.2011.13},
	language = {en},
	urldate = {2023-11-16},
	booktitle = {2011 {IEEE}/{ACM} 12th {International} {Conference} on {Grid} {Computing}},
	publisher = {IEEE},
	author = {Feller, Eugen and Rilling, Louis and Morin, Christine},
	month = sep,
	year = {2011},
	pages = {26--33},
}

@inproceedings{pop_swarm-inspired_2012,
	address = {Craiova Romania},
	title = {A swarm-inspired data center consolidation methodology},
	isbn = {978-1-4503-0915-8},
	url = {https://dl.acm.org/doi/10.1145/2254129.2254180},
	doi = {10.1145/2254129.2254180},
	abstract = {This paper proposes a swarm-inspired data center consolidation methodology which aims at reducing the power consumption in data centers while ensuring the workload execution within the pre-established performance parameters. Each data center server is managed by an intelligent agent that deals with its power efficiency by implementing a bird’s migration-inspired behavior to decide on the appropriate server consolidation actions. The selected actions are executed to achieve an optimal utilization of server computing resources thus lowering power consumption. The data center servers self-organize in logical clusters according to the birds V-formation self-organizing migration model. The results are promising showing that the swarm-inspired data center consolidation methodology optimizes the utilization ratio of the data center computing resources and achieves estimated power savings of about 16\%.},
	language = {en},
	urldate = {2023-11-16},
	booktitle = {Proceedings of the 2nd {International} {Conference} on {Web} {Intelligence}, {Mining} and {Semantics}},
	publisher = {ACM},
	author = {Pop, Cristina Bianca and Anghel, Ionut and Cioara, Tudor and Salomie, Ioan and Vartic, Iulia},
	month = jun,
	year = {2012},
	pages = {1--7},
}

@article{liang_energy-aware_2021,
	title = {An energy-aware resource deployment algorithm for cloud data centers based on dynamic hybrid machine learning},
	volume = {222},
	issn = {09507051},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0950705121002835},
	doi = {10.1016/j.knosys.2021.107020},
	abstract = {To meet the ever-increasing requirements of cloud users, cloud service providers have further increased the deployment of cloud data centers. Cloud users can freely choose the cloud data center that suits them according to their own business characteristics and budget expenditures. This requires cloud service providers to continuously improve service quality and reduce usage costs to expand their own user base. Mature cloud service providers will continuously optimize cloud tasks and virtual machine deployment methods to increase physical machine utilization and reduce cloud data center energy consumption. However, existing virtual machine deployment algorithms usually have low utilization of physical machines or high energy consumption of cloud data centers, thereby reducing the frequency of use by cloud users and the benefits of cloud service providers. This paper systematically analyzes virtual machine and physical machine models. At the same time, the K-means clustering algorithm for unsupervised learning and the KNN classification algorithm for supervised learning are expanded to establish a dynamic hybrid resource deployment rule. Then, an energy-aware resource deployment algorithm for cloud data centers based on dynamic hybrid machine learning (EHML) is proposed based on the theory of machine learning. This algorithm reduces energy consumption by increasing the average utilization of physical machines. Finally, the experimental test results show that the average utilization of physical machines and energy consumption of the algorithm are significantly better than those of the comparison algorithms.},
	language = {en},
	urldate = {2023-11-30},
	journal = {Knowledge-Based Systems},
	author = {Liang, Bin and Wu, Di and Wu, Pengfei and Su, Yuanqi},
	month = jun,
	year = {2021},
	pages = {107020},
}

@inproceedings{berral_towards_2010,
	address = {Passau Germany},
	title = {Towards energy-aware scheduling in data centers using machine learning},
	isbn = {978-1-4503-0042-1},
	doi = {10.1145/1791314.1791349},
	abstract = {As energy-related costs have become a major economical factor for IT infrastructures and data-centers, companies and the research community are being challenged to ﬁnd better and more eﬃcient power-aware resource management strategies. There is a growing interest in “Green” IT and there is still a big gap in this area to be covered.},
	language = {en},
	urldate = {2023-11-30},
	booktitle = {Proceedings of the 1st {International} {Conference} on {Energy}-{Efficient} {Computing} and {Networking}},
	publisher = {ACM},
	author = {Berral, Josep Ll. and Goiri, Iñigo and Nou, Ramón and Julià, Ferran and Guitart, Jordi and Gavaldà, Ricard and Torres, Jordi},
	month = apr,
	year = {2010},
}

@article{seyfollahi_towards_2023,
	title = {Towards developing a machine learning-metaheuristic-enhanced energy-sensitive routing framework for the internet of things},
	volume = {96},
	issn = {01419331},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0141933122002769},
	doi = {10.1016/j.micpro.2022.104747},
	abstract = {The heterogeneous nature, communication constraints, multi-hop data transmissions, and inherent challenges of wireless connections have caused routing and data transmission processes to play a vital role in the Internet of Things (IoT) infrastructures efficiency and stability. Energy efficiency and optimal load equilibrium between sensing devices are fundamental challenges due to the limitation of energy resources in IoT devices. Considering the cruciality of prolonging IoT networks and the NP-hard nature of energy optimization in heterogeneous and distributed IoT infrastructures, this research represents a hybrid energy-aware protocol for data routing in IoT. It is deployed based on Machine Learning (ML) and metaheuristic HTOA (Heat Transfer Optimizer). The proposed protocol adopts a four-phase approach for fuzzy clustering, predicting energy consumption based on Support Vector Regression (SVR) and time series techniques, selecting optimal cluster heads (CH) considering energy and centralization factors, and routing and data transmission from each sensor to and from CH to the sink using Ant Colony Optimization (ACO) algorithm. The simulation outputs revealed that our scheme performs more effi­ ciently in energy consumption, end-to-end delay (EtED), load balancing, overhead, and network lifetime in all designed scenarios compared to other methods.},
	language = {en},
	urldate = {2023-12-01},
	journal = {Microprocessors and Microsystems},
	author = {Seyfollahi, Ali and Taami, Tania and Ghaffari, Ali},
	month = feb,
	year = {2023},
	pages = {104747},
}

@article{siegmund_green_nodate,
	title = {Green {Conﬁguration}: {Can} {AI} {Help} {Reduce} {Energy} {Consumption} of {Conﬁgurable} {Software} {Systems}?},
	abstract = {Reducing energy consumption of IT-systems is fundamentally important for saving cost and reducing CO2 emissions. A largely untapped potential arises from the conﬁguration options a software system provides to adapt it to the application scenario, workload, and underlying hardware. As applying methods from artiﬁcial intelligence (AI) and machine learning (ML) has been a success story for performance optimization, it is tempting to expect similar beneﬁts for energy. We review proposed and potential techniques from AI for reducing energy consumption and discuss why energy, unlike performance, requires an approach that is closely intertwined with other software-engineering (SE) methods. We explain the limits of pure AI/ML methods when focusing on the source code and outline a conceptual framework for combining SE methods and ML to build white-box energy models. This way, researchers and practitioners are guided towards promising techniques, including explicit modelling of uncertainty of energy estimates and identiﬁcation of causal relationships of conﬁguration options to energy leaks.},
	language = {en},
	author = {Siegmund, Norbert and Dorn, Johannes and Weber, Max and Kaltenecker, Christian and Apel, Sven},
}

@article{osypanka_resource_2022,
	title = {Resource {Usage} {Cost} {Optimization} in {Cloud} {Computing} {Using} {Machine} {Learning}},
	volume = {10},
	issn = {2168-7161, 2372-0018},
	url = {https://ieeexplore.ieee.org/document/9165211/},
	doi = {10.1109/TCC.2020.3015769},
	abstract = {Cloud computing is gaining popularity among small and medium-sized enterprises. The cost of cloud resources plays a signiﬁcant role for these companies and this is why cloud resource optimization has become a very important issue. Numerous methods have been proposed to optimize cloud computing resources according to actual demand and to reduce the cost of cloud services. Such approaches mostly focus on a single factor (i.e. compute power) optimization, but this can yield unsatisfactory results in real-world cloud workloads which are multi-factor, dynamic and irregular. This paper presents a novel approach which uses anomaly detection, machine learning and particle swarm optimization to achieve a cost-optimal cloud resource conﬁguration. It is a complete solution which works in a closed loop without the need for external supervision or initialization, builds knowledge about the usage patterns of the system being optimized and ﬁlters out anomalous situations on the ﬂy. Our solution can adapt to changes in both system load and the cloud provider’s pricing plan. It was tested in Microsoft’s cloud environment Azure using data collected from a real-life system. Experiments demonstrate that over a period of 10 months, a cost reduction of 85\% was achieved.},
	language = {en},
	number = {3},
	urldate = {2023-12-02},
	journal = {IEEE Transactions on Cloud Computing},
	author = {Osypanka, Patryk and Nawrocki, Piotr},
	month = jul,
	year = {2022},
	pages = {2079--2089},
}
